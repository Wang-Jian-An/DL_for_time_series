{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/energydata_complete.csv\")\n",
    "\n",
    "target_name = \"Appliances\"\n",
    "continuous_features = [\n",
    "    \"lights\",\n",
    "    \"T1\", \n",
    "    \"RH_1\",\n",
    "    \"T2\",\n",
    "    \"RH_2\",\n",
    "    \"T3\",\n",
    "    \"RH_3\",\n",
    "    \"T4\",\n",
    "    \"RH_4\",\n",
    "    \"T5\",\n",
    "    \"RH_5\",\n",
    "    \"T6\",\n",
    "    \"RH_6\",\n",
    "    \"T7\",\n",
    "    \"RH_7\",\n",
    "    \"T8\",\n",
    "    \"RH_8\",\n",
    "    \"T9\",\n",
    "    \"RH_9\",\n",
    "    \"T_out\",\n",
    "    \"RH_out\",\n",
    "    \"Press_mm_hg\",\n",
    "    \"Windspeed\"\n",
    "]\n",
    "during_training = 15\n",
    "after_prediction = 5\n",
    "data_groups = df.shape[0] // (during_training + after_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = list()\n",
    "y = list()\n",
    "for one_batch in range(data_groups):\n",
    "    X.append(df[continuous_features].iloc[one_batch:during_training+one_batch].values.tolist())\n",
    "    y.append(df[target_name].iloc[during_training+after_prediction+one_batch])\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, test_size = 0.2, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(788, 15, 23)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DL_layers = [\n",
    "    {\n",
    "        \"RNN\": {\n",
    "            \"input_size\": train_X.shape[-1],\n",
    "            \"hidden_size\": train_X.shape[-1] // 2,\n",
    "            \"num_layers\": 3,\n",
    "            \"bidirectional\": True\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"self-attention\": {\n",
    "            \"embed_size\": train_X.shape[-1] // 2 * 2,\n",
    "            \"target_length\": train_X.shape[1],\n",
    "            \"target_compression_length\": 3,\n",
    "            \"num_heads\": 2\n",
    "        }\n",
    "    }, \n",
    "    {\n",
    "        \"LSTM\": {\n",
    "            \"input_size\": train_X.shape[-1] // 2 * 2,\n",
    "            \"hidden_size\": 1,\n",
    "            \"num_layers\": 3,\n",
    "            \"bidirectional\": True\n",
    "        }        \n",
    "    },\n",
    "    {\n",
    "        \"flatten\": {}        \n",
    "    },\n",
    "    {\n",
    "        \"linear\": {\n",
    "            \"in_features\": train_X.shape[1] * 2,\n",
    "            \"out_features\": 1\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape[-1] // 2 * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_model(\n",
      "  (model): Sequential(\n",
      "    (0): RNN_block(\n",
      "      (model): RNN(23, 11, num_layers=3, batch_first=True, bidirectional=True)\n",
      "    )\n",
      "    (1): self_attention_block(\n",
      "      (model): MultiheadAttention(\n",
      "        (out_proj): NonDynamicallyQuantizableLinear(in_features=110, out_features=110, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (2): LSTM_block(\n",
      "      (model): LSTM(22, 1, num_layers=3, batch_first=True, bidirectional=True)\n",
      "    )\n",
      "    (3): Flatten(start_dim=1, end_dim=-1)\n",
      "    (4): Linear(in_features=30, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "Epoch:  0 Train Loss:  30853.971005859374 Test Loss:  26267.772611177883\n",
      "Epoch:  1 Train Loss:  30744.86888671875 Test Loss:  26131.618802584133\n",
      "Epoch:  2 Train Loss:  30545.506240234376 Test Loss:  25891.03718449519\n",
      "Epoch:  3 Train Loss:  30221.555439453125 Test Loss:  25541.887263371395\n",
      "Epoch:  4 Train Loss:  29812.734716796876 Test Loss:  25151.67559344952\n",
      "Epoch:  5 Train Loss:  29336.849418945312 Test Loss:  24675.969069260816\n",
      "Epoch:  6 Train Loss:  28826.595581054688 Test Loss:  24206.774282602164\n",
      "Epoch:  7 Train Loss:  28311.5333203125 Test Loss:  23758.517559344953\n",
      "Epoch:  8 Train Loss:  27842.204291992188 Test Loss:  23378.72502253606\n",
      "Epoch:  9 Train Loss:  27412.452543945314 Test Loss:  22971.37218299279\n",
      "Epoch:  10 Train Loss:  26993.74931152344 Test Loss:  22598.64220252404\n",
      "Epoch:  11 Train Loss:  26615.294248046874 Test Loss:  22298.16604379507\n",
      "Epoch:  12 Train Loss:  26259.471606445313 Test Loss:  21974.37153508113\n",
      "Epoch:  13 Train Loss:  25967.430698242188 Test Loss:  21700.66962139423\n",
      "Epoch:  14 Train Loss:  25653.15126220703 Test Loss:  21432.449528620793\n",
      "Epoch:  15 Train Loss:  25339.760151367187 Test Loss:  21142.331787109375\n",
      "Epoch:  16 Train Loss:  25043.94321533203 Test Loss:  20875.55417104868\n",
      "Epoch:  17 Train Loss:  24796.58690185547 Test Loss:  20679.644775390625\n",
      "Epoch:  18 Train Loss:  24534.238239746093 Test Loss:  20406.999990609977\n",
      "Epoch:  19 Train Loss:  24282.296501464843 Test Loss:  20226.107778695914\n",
      "Epoch:  20 Train Loss:  24054.918081054686 Test Loss:  19987.356464092547\n",
      "Epoch:  21 Train Loss:  23799.061501464843 Test Loss:  19749.467247596152\n",
      "Epoch:  22 Train Loss:  23578.262163085936 Test Loss:  19621.51209435096\n",
      "Epoch:  23 Train Loss:  23374.70765625 Test Loss:  19403.54466364934\n",
      "Epoch:  24 Train Loss:  23164.441149902344 Test Loss:  19258.819274902344\n",
      "Epoch:  25 Train Loss:  22965.12390625 Test Loss:  19064.212505634016\n",
      "Epoch:  26 Train Loss:  22750.762153320313 Test Loss:  18953.792799729566\n",
      "Epoch:  27 Train Loss:  22573.351983642577 Test Loss:  18741.27839073768\n",
      "Epoch:  28 Train Loss:  22402.261630859375 Test Loss:  18573.82405442458\n",
      "Epoch:  29 Train Loss:  22222.686474609374 Test Loss:  18416.26730111929\n"
     ]
    }
   ],
   "source": [
    "from DL_for_time_series import DL_time_series_training_flow\n",
    "training_obj = DL_time_series_training_flow(\n",
    "    DL_layers = DL_layers,\n",
    "    loss_func = \"mse\",\n",
    "    optimizer = \"adam\",\n",
    "    epochs = 30,\n",
    "    target_type = \"regression\"\n",
    ")\n",
    "result = training_obj.fit(\n",
    "    train_X = train_X,\n",
    "    train_y = train_y,\n",
    "    test_X = test_X,\n",
    "    test_y = test_y,\n",
    "    batch_size = 16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.12.4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
