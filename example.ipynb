{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/energydata_complete.csv\")\n",
    "\n",
    "target_name = \"Appliances\"\n",
    "continuous_features = [\n",
    "    \"lights\",\n",
    "    \"T1\", \n",
    "    \"RH_1\",\n",
    "    \"T2\",\n",
    "    \"RH_2\",\n",
    "    \"T3\",\n",
    "    \"RH_3\",\n",
    "    \"T4\",\n",
    "    \"RH_4\",\n",
    "    \"T5\",\n",
    "    \"RH_5\",\n",
    "    \"T6\",\n",
    "    \"RH_6\",\n",
    "    \"T7\",\n",
    "    \"RH_7\",\n",
    "    \"T8\",\n",
    "    \"RH_8\",\n",
    "    \"T9\",\n",
    "    \"RH_9\",\n",
    "    \"T_out\",\n",
    "    \"RH_out\",\n",
    "    \"Press_mm_hg\",\n",
    "    \"Windspeed\"\n",
    "]\n",
    "during_training = 15\n",
    "after_prediction = 5\n",
    "data_groups = df.shape[0] // (during_training + after_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = list()\n",
    "y = list()\n",
    "for one_batch in range(data_groups):\n",
    "    X.append(df[continuous_features].iloc[one_batch:during_training+one_batch].values.tolist())\n",
    "    y.append(df[target_name].iloc[during_training+after_prediction+one_batch])\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, test_size = 0.2, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(788, 15, 23)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DL_layers = [\n",
    "    {\n",
    "        \"RNN\": {\n",
    "            \"input_size\": train_X.shape[-1],\n",
    "            \"hidden_size\": train_X.shape[-1] // 2,\n",
    "            \"num_layers\": 3,\n",
    "            \"bidirectional\": True\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"self-attention\": {\n",
    "            \"embed_size\": train_X.shape[-1] // 2 * 2,\n",
    "            \"target_length\": train_X.shape[1],\n",
    "            \"target_compression_length\": 3,\n",
    "            \"num_heads\": 2\n",
    "        }\n",
    "    }, \n",
    "    {\n",
    "        \"LSTM\": {\n",
    "            \"input_size\": train_X.shape[-1] // 2 * 2,\n",
    "            \"hidden_size\": 1,\n",
    "            \"num_layers\": 3,\n",
    "            \"bidirectional\": True\n",
    "        }        \n",
    "    },\n",
    "    {\n",
    "        \"flatten\": {}        \n",
    "    },\n",
    "    {\n",
    "        \"linear\": {\n",
    "            \"in_features\": train_X.shape[1] * 2,\n",
    "            \"out_features\": 1\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape[-1] // 2 * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_model(\n",
      "  (model): Sequential(\n",
      "    (0): RNN_block(\n",
      "      (model): RNN(23, 11, num_layers=3, batch_first=True, bidirectional=True)\n",
      "    )\n",
      "    (1): self_attention_block(\n",
      "      (model): MultiheadAttention(\n",
      "        (out_proj): NonDynamicallyQuantizableLinear(in_features=110, out_features=110, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (2): LSTM_block(\n",
      "      (model): LSTM(22, 1, num_layers=3, batch_first=True, bidirectional=True)\n",
      "    )\n",
      "    (3): Flatten(start_dim=1, end_dim=-1)\n",
      "    (4): Linear(in_features=30, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "Epoch:  0 Train Loss:  31670.179560546876 Test Loss:  22849.511005108172\n",
      "Epoch:  1 Train Loss:  31536.877236328124 Test Loss:  22706.83916766827\n",
      "Epoch:  2 Train Loss:  31315.0262109375 Test Loss:  22440.989595853367\n",
      "Epoch:  3 Train Loss:  30864.714921875 Test Loss:  21910.84814453125\n",
      "Epoch:  4 Train Loss:  30237.280625 Test Loss:  21408.97644981971\n",
      "Epoch:  5 Train Loss:  29709.12625 Test Loss:  20969.460298978367\n",
      "Epoch:  6 Train Loss:  29242.502177734375 Test Loss:  20620.405451847957\n",
      "Epoch:  7 Train Loss:  28833.5037109375 Test Loss:  20282.210317758414\n",
      "Epoch:  8 Train Loss:  28430.461040039063 Test Loss:  19957.005943885215\n",
      "Epoch:  9 Train Loss:  28071.291630859374 Test Loss:  19660.156804011418\n",
      "Epoch:  10 Train Loss:  27746.041298828124 Test Loss:  19405.73393366887\n",
      "Epoch:  11 Train Loss:  27433.769809570313 Test Loss:  19120.279681865984\n",
      "Epoch:  12 Train Loss:  27128.069057617187 Test Loss:  18854.55368276743\n",
      "Epoch:  13 Train Loss:  26810.9007421875 Test Loss:  18636.525634765625\n",
      "Epoch:  14 Train Loss:  26536.738823242187 Test Loss:  18399.296513484074\n",
      "Epoch:  15 Train Loss:  26259.766694335936 Test Loss:  18168.377347506008\n",
      "Epoch:  16 Train Loss:  25997.689194335937 Test Loss:  17960.2764845628\n",
      "Epoch:  17 Train Loss:  25739.465141601562 Test Loss:  17735.501272348258\n",
      "Epoch:  18 Train Loss:  25490.24479003906 Test Loss:  17526.730487530047\n",
      "Epoch:  19 Train Loss:  25236.662094726562 Test Loss:  17336.035287710336\n",
      "Epoch:  20 Train Loss:  25026.49390625 Test Loss:  17182.692969689004\n",
      "Epoch:  21 Train Loss:  24771.29787109375 Test Loss:  16991.449049729566\n",
      "Epoch:  22 Train Loss:  24541.36677734375 Test Loss:  16801.897629957934\n",
      "Epoch:  23 Train Loss:  24349.950668945312 Test Loss:  16602.075228177586\n",
      "Epoch:  24 Train Loss:  24134.64744140625 Test Loss:  16470.534729003906\n",
      "Epoch:  25 Train Loss:  23921.87337158203 Test Loss:  16299.60757446289\n",
      "Epoch:  26 Train Loss:  23748.110783691405 Test Loss:  16156.435347336988\n",
      "Epoch:  27 Train Loss:  23543.769934082033 Test Loss:  15988.79739849384\n",
      "Epoch:  28 Train Loss:  23337.67529296875 Test Loss:  15806.794499323918\n",
      "Epoch:  29 Train Loss:  23150.65381347656 Test Loss:  15725.711604191707\n"
     ]
    }
   ],
   "source": [
    "from DL_for_time_series import DL_time_series_training_flow\n",
    "training_obj = DL_time_series_training_flow(\n",
    "    DL_layers = DL_layers,\n",
    "    loss_func = \"mse\",\n",
    "    optimizer = \"adam\",\n",
    "    epochs = 30,\n",
    "    target_type = \"regression\"\n",
    ")\n",
    "result = training_obj.fit(\n",
    "    train_X = train_X,\n",
    "    train_y = train_y,\n",
    "    test_X = test_X,\n",
    "    test_y = test_y,\n",
    "    batch_size = 16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.12.4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
